{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e7b19a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Display / debugging\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96a79649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/saber/NEST\n",
      "Intermediate data path: /home/saber/NEST/data/intermediate\n",
      "Master output path: /home/saber/NEST/data/master\n"
     ]
    }
   ],
   "source": [
    "# Project root\n",
    "PROJECT_ROOT = Path(\"..\")\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "INTERMEDIATE_DIR = DATA_DIR / \"intermediate\"\n",
    "MASTER_DIR = DATA_DIR / \"master\"\n",
    "\n",
    "# Create master directory if not exists\n",
    "MASTER_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT.resolve())\n",
    "print(\"Intermediate data path:\", INTERMEDIATE_DIR.resolve())\n",
    "print(\"Master output path:\", MASTER_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cdb38c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide files into buckets for processing\n",
    "FILES = {\n",
    "    # Bucket A\n",
    "    \"cpid\": INTERMEDIATE_DIR / \"cpid_edc_metrics_agg.parquet\",\n",
    "    \"edrr\": INTERMEDIATE_DIR / \"compiled_edrr_agg.parquet\",\n",
    "\n",
    "    # Bucket B\n",
    "    \"visit_projection\": INTERMEDIATE_DIR / \"visit_projection_tracker_agg.parquet\",\n",
    "    \"missing_pages\": INTERMEDIATE_DIR / \"global_missing_pages_agg.parquet\",\n",
    "    \"inactivated_forms\": INTERMEDIATE_DIR / \"inactivated_forms_loglines_agg.parquet\",\n",
    "    \"missing_labs\": INTERMEDIATE_DIR / \"missing_lab_issues_agg.parquet\",\n",
    "    \"sae_dashboard\": INTERMEDIATE_DIR / \"sae_dashboard_agg.parquet\",\n",
    "\n",
    "    # Bucket C\n",
    "    \"coding_meddra\": INTERMEDIATE_DIR / \"coding_reports_agg.parquet\",\n",
    "    \"coding_whodrug\": INTERMEDIATE_DIR / \"coding_reports_whodra_agg.parquet\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "002b8baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parquet(path: Path) -> pd.DataFrame:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing file: {path}\")\n",
    "    df = pd.read_parquet(path)\n",
    "    print(f\"Loaded {path.name} | shape = {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e38171ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpid                 : OK\n",
      "edrr                 : OK\n",
      "visit_projection     : OK\n",
      "missing_pages        : OK\n",
      "inactivated_forms    : OK\n",
      "missing_labs         : OK\n",
      "sae_dashboard        : OK\n",
      "coding_meddra        : OK\n",
      "coding_whodrug       : OK\n"
     ]
    }
   ],
   "source": [
    "for name, path in FILES.items():\n",
    "    print(f\"{name:20s} : {'OK' if path.exists() else 'MISSING'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3c0ccae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cpid_edc_metrics_agg.parquet | shape = (5461, 11)\n",
      "Loaded compiled_edrr_agg.parquet | shape = (581, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load Bucket A datasets (spine)\n",
    "cpid_df = load_parquet(FILES[\"cpid\"])\n",
    "edrr_df = load_parquet(FILES[\"edrr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeef62af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check required columns in CPID\n",
    "REQUIRED_CPID_KEYS = [\"study_id\", \"site_id\", \"subject_id\"]\n",
    "\n",
    "for col in REQUIRED_CPID_KEYS:\n",
    "    assert col in cpid_df.columns, f\"CPID missing required key column: {col}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b75000e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No null identifiers\n",
    "assert cpid_df[REQUIRED_CPID_KEYS].isnull().sum().sum() == 0, \\\n",
    "    \"Null values found in CPID primary keys\"\n",
    "\n",
    "# Grain validation: one row per study-site-subject\n",
    "dup_count = (\n",
    "    cpid_df\n",
    "    .duplicated(subset=REQUIRED_CPID_KEYS)\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "assert dup_count == 0, f\"CPID violates grain: {dup_count} duplicate subject rows\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98ca16a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check required columns in EDRR\n",
    "REQUIRED_EDRR_KEYS = [\"study_id\", \"subject_id\"]\n",
    "\n",
    "for col in REQUIRED_EDRR_KEYS:\n",
    "    assert col in edrr_df.columns, f\"EDRR missing required key column: {col}\"\n",
    "\n",
    "# No null identifiers\n",
    "assert edrr_df[REQUIRED_EDRR_KEYS].isnull().sum().sum() == 0, \\\n",
    "    \"Null values found in EDRR primary keys\"\n",
    "\n",
    "# Grain validation: one row per study-subject\n",
    "dup_count = (\n",
    "    edrr_df\n",
    "    .duplicated(subset=REQUIRED_EDRR_KEYS)\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "assert dup_count == 0, f\"EDRR violates grain: {dup_count} duplicate subject rows\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "850a8834",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = (\n",
    "    cpid_df[[\"study_id\", \"site_id\", \"subject_id\"]]\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "master_df[\"master_subject_id\"] = (\n",
    "    master_df[\"study_id\"].astype(str) + \"|\" +\n",
    "    master_df[\"site_id\"].astype(str) + \"|\" +\n",
    "    master_df[\"subject_id\"].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26630bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master subject index created: 5461 subjects\n"
     ]
    }
   ],
   "source": [
    "# Uniqueness\n",
    "assert master_df[\"master_subject_id\"].is_unique, \\\n",
    "    \"Master subject ID is not unique\"\n",
    "\n",
    "# Row count must exactly match CPID\n",
    "assert len(master_df) == len(cpid_df), \\\n",
    "    \"Master index row count mismatch with CPID\"\n",
    "\n",
    "print(f\"Master subject index created: {len(master_df)} subjects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8ae066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.merge(\n",
    "    edrr_df,\n",
    "    on=[\"study_id\", \"subject_id\"],\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3880f197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure no row explosion\n",
    "assert len(master_df) == len(cpid_df), \\\n",
    "    \"Row count changed after joining EDRR (unexpected)\"\n",
    "\n",
    "# Phase 1 canonical EDRR column name\n",
    "EDRR_RAW_COL = \"total_open_issue_count_per_subject\"\n",
    "\n",
    "assert EDRR_RAW_COL in master_df.columns, \\\n",
    "    f\"Expected EDRR column missing: {EDRR_RAW_COL}\"\n",
    "\n",
    "# Normalize into Phase 2 canonical metric\n",
    "master_df[\"edrr_open_issues_count\"] = (\n",
    "    master_df[EDRR_RAW_COL]\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# Optional safety check\n",
    "assert (master_df[\"edrr_open_issues_count\"] >= 0).all(), \\\n",
    "    \"Negative EDRR issue counts detected\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12be703c",
   "metadata": {},
   "source": [
    "# Step 3 Loading aggregrate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf93e62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded visit_projection_tracker_agg.parquet | shape = (143, 5)\n"
     ]
    }
   ],
   "source": [
    "visit_df = load_parquet(FILES[\"visit_projection\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87dccbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_VISIT_COLS = [\n",
    "    \"site_id\",\n",
    "    \"subject_id\",\n",
    "    \"num_days_outstanding\"\n",
    "]\n",
    "\n",
    "for col in REQUIRED_VISIT_COLS:\n",
    "    assert col in visit_df.columns, f\"Visit Projection missing column: {col}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab126b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No null identifiers\n",
    "assert visit_df[[\"site_id\", \"subject_id\"]].isnull().sum().sum() == 0, \\\n",
    "    \"Null site_id / subject_id in Visit Projection Tracker\"\n",
    "\n",
    "# days_outstanding must be numeric\n",
    "assert pd.api.types.is_numeric_dtype(visit_df[\"num_days_outstanding\"]), \\\n",
    "    \"days_outstanding must be numeric\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6489522",
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_df = visit_df[visit_df[\"num_days_outstanding\"] > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "685b2878",
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_agg = (\n",
    "    visit_df\n",
    "    .groupby([\"site_id\", \"subject_id\"], as_index=False)\n",
    "    .agg(\n",
    "        missing_visits_count=(\"num_days_outstanding\", \"count\"),\n",
    "        max_days_visit_overdue=(\"num_days_outstanding\", \"max\")\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "609fa83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grain validation\n",
    "dup_count = (\n",
    "    visit_agg\n",
    "    .duplicated(subset=[\"site_id\", \"subject_id\"])\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "assert dup_count == 0, \\\n",
    "    f\"Visit aggregation violated grain: {dup_count} duplicate rows\"\n",
    "\n",
    "# Sanity checks\n",
    "assert (visit_agg[\"missing_visits_count\"] > 0).all(), \\\n",
    "    \"missing_visits_count must be positive\"\n",
    "\n",
    "assert (visit_agg[\"max_days_visit_overdue\"] > 0).all(), \\\n",
    "    \"max_days_visit_overdue must be positive\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "798671a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.merge(\n",
    "    visit_agg,\n",
    "    on=[\"site_id\", \"subject_id\"],\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8931d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row count must not change\n",
    "assert len(master_df) == len(cpid_df), \\\n",
    "    \"Row count changed after Visit Projection join\"\n",
    "\n",
    "# Fill missing values (no overdue visits)\n",
    "master_df[\"missing_visits_count\"] = (\n",
    "    master_df[\"missing_visits_count\"]\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "master_df[\"max_days_visit_overdue\"] = (\n",
    "    master_df[\"max_days_visit_overdue\"]\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# Final sanity\n",
    "assert (master_df[\"missing_visits_count\"] >= 0).all()\n",
    "assert (master_df[\"max_days_visit_overdue\"] >= 0).all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d1635f",
   "metadata": {},
   "source": [
    "##### Loading Global Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8ecce23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded global_missing_pages_agg.parquet | shape = (21, 5)\n"
     ]
    }
   ],
   "source": [
    "missing_pages_df = load_parquet(FILES[\"missing_pages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ff7a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_MISSING_PAGE_COLS = [\n",
    "    \"study_id\",\n",
    "    \"site_id\",\n",
    "    \"subject_id\",\n",
    "    \"num_of_days_missing\"\n",
    "]\n",
    "\n",
    "for col in REQUIRED_MISSING_PAGE_COLS:\n",
    "    assert col in missing_pages_df.columns, \\\n",
    "        f\"Missing Pages dataset missing column: {col}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "965fb004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No null identifiers\n",
    "assert missing_pages_df[[\"study_id\", \"site_id\", \"subject_id\"]].isnull().sum().sum() == 0, \\\n",
    "    \"Null identifiers found in Missing Pages dataset\"\n",
    "\n",
    "# days_page_missing must be numeric\n",
    "assert pd.api.types.is_numeric_dtype(missing_pages_df[\"num_of_days_missing\"]), \\\n",
    "    \"num_of_days_missing must be numeric\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e23432f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_pages_df = missing_pages_df[\n",
    "    missing_pages_df[\"num_of_days_missing\"] > 0\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ca35901",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_pages_agg = (\n",
    "    missing_pages_df\n",
    "    .groupby([\"study_id\", \"site_id\", \"subject_id\"], as_index=False)\n",
    "    .agg(\n",
    "        missing_pages_count=(\"num_of_days_missing\", \"count\"),\n",
    "        max_days_page_missing=(\"num_of_days_missing\", \"max\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2fce475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grain validation\n",
    "dup_count = (\n",
    "    missing_pages_agg\n",
    "    .duplicated(subset=[\"study_id\", \"site_id\", \"subject_id\"])\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "assert dup_count == 0, \\\n",
    "    f\"Missing Pages aggregation violated grain: {dup_count} duplicates\"\n",
    "\n",
    "# Sanity checks\n",
    "assert (missing_pages_agg[\"missing_pages_count\"] > 0).all()\n",
    "assert (missing_pages_agg[\"max_days_page_missing\"] > 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b82287ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.merge(\n",
    "    missing_pages_agg,\n",
    "    on=[\"study_id\", \"site_id\", \"subject_id\"],\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "611e5a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No row explosion\n",
    "assert len(master_df) == len(cpid_df), \\\n",
    "    \"Row count changed after Missing Pages join\"\n",
    "\n",
    "# Fill defaults (no missing pages)\n",
    "master_df[\"missing_pages_count\"] = (\n",
    "    master_df[\"missing_pages_count\"]\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "master_df[\"max_days_page_missing\"] = (\n",
    "    master_df[\"max_days_page_missing\"]\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# Final sanity\n",
    "assert (master_df[\"missing_pages_count\"] >= 0).all()\n",
    "assert (master_df[\"max_days_page_missing\"] >= 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4d541a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded missing_lab_issues_agg.parquet | shape = (695, 8)\n"
     ]
    }
   ],
   "source": [
    "# Missing Labs\n",
    "labs_df = load_parquet(FILES[\"missing_labs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6aa2f365",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_LAB_COLS = [\n",
    "    \"study_id\",\n",
    "    \"site_id\",\n",
    "    \"subject_id\",\n",
    "    \"num_lab_issues\",\n",
    "    \"num_missing_lab_name\",\n",
    "    \"num_missing_ranges_units\"\n",
    "]\n",
    "\n",
    "for col in REQUIRED_LAB_COLS:\n",
    "    assert col in labs_df.columns, \\\n",
    "        f\"Missing Labs dataset missing column: {col}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d911607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No null identifiers\n",
    "assert labs_df[[\"study_id\", \"site_id\", \"subject_id\"]].isnull().sum().sum() == 0, \\\n",
    "    \"Null identifiers in Missing Labs dataset\"\n",
    "\n",
    "# Numeric checks\n",
    "for col in [\n",
    "    \"num_lab_issues\",\n",
    "    \"num_missing_lab_name\",\n",
    "    \"num_missing_ranges_units\"\n",
    "]:\n",
    "    assert pd.api.types.is_numeric_dtype(labs_df[col]), \\\n",
    "        f\"{col} must be numeric\"\n",
    "\n",
    "    assert (labs_df[col] >= 0).all(), \\\n",
    "        f\"Negative values detected in {col}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63a4b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_agg = labs_df.copy()\n",
    "\n",
    "labs_agg[\"missing_lab_issues_count\"] = labs_agg[\"num_lab_issues\"].astype(int)\n",
    "\n",
    "labs_agg[\"lab_ranges_missing_flag\"] = (\n",
    "    labs_agg[\"num_missing_ranges_units\"] > 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9599efaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_count = (\n",
    "    labs_agg\n",
    "    .duplicated(subset=[\"study_id\", \"site_id\", \"subject_id\"])\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "assert dup_count == 0, \\\n",
    "    f\"Missing Labs violates grain: {dup_count} duplicate rows\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5e174b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_agg = labs_agg[\n",
    "    [\n",
    "        \"study_id\",\n",
    "        \"site_id\",\n",
    "        \"subject_id\",\n",
    "        \"missing_lab_issues_count\",\n",
    "        \"lab_ranges_missing_flag\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1310a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.merge(\n",
    "    labs_agg,\n",
    "    on=[\"study_id\", \"site_id\", \"subject_id\"],\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "427c2751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No row explosion\n",
    "assert len(master_df) == len(cpid_df), \\\n",
    "    \"Row count changed after Missing Labs join\"\n",
    "\n",
    "# Fill defaults (no lab issues)\n",
    "master_df[\"missing_lab_issues_count\"] = (\n",
    "    master_df[\"missing_lab_issues_count\"]\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "master_df[\"lab_ranges_missing_flag\"] = (\n",
    "    master_df[\"lab_ranges_missing_flag\"]\n",
    "    .fillna(False)\n",
    "    .astype(bool)\n",
    ")\n",
    "\n",
    "# Final sanity\n",
    "assert (master_df[\"missing_lab_issues_count\"] >= 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "992321ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sae_dashboard_agg.parquet | shape = (5543, 10)\n"
     ]
    }
   ],
   "source": [
    "# SAE Dashboard\n",
    "sae_df = load_parquet(FILES[\"sae_dashboard\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a84d3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_SAE_COLS = [\n",
    "    \"study_id\",\n",
    "    \"site_id\",\n",
    "    \"subject_id\",\n",
    "    \"num_open_sae\",\n",
    "    \"num_review_pending\",\n",
    "    \"num_action_pending\",\n",
    "    \"num_case_open\",\n",
    "]\n",
    "\n",
    "for col in REQUIRED_SAE_COLS:\n",
    "    assert col in sae_df.columns, \\\n",
    "        f\"SAE dataset missing required column: {col}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3116c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No null identifiers\n",
    "assert sae_df[[\"study_id\", \"site_id\", \"subject_id\"]].isnull().sum().sum() == 0, \\\n",
    "    \"Null identifiers in SAE dataset\"\n",
    "\n",
    "# Numeric safety checks\n",
    "for col in [\n",
    "    \"num_open_sae\",\n",
    "    \"num_review_pending\",\n",
    "    \"num_action_pending\",\n",
    "    \"num_case_open\",\n",
    "]:\n",
    "    assert pd.api.types.is_numeric_dtype(sae_df[col]), \\\n",
    "        f\"{col} must be numeric\"\n",
    "\n",
    "    assert (sae_df[col] >= 0).all(), \\\n",
    "        f\"Negative values detected in {col}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c4965bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_agg = sae_df.copy()\n",
    "\n",
    "# Canonical count\n",
    "sae_agg[\"open_sae_count\"] = sae_agg[\"num_open_sae\"].astype(int)\n",
    "\n",
    "# Pending reviews / actions are treated as blocking flags\n",
    "sae_agg[\"pending_sae_dm_review_flag\"] = (\n",
    "    (sae_agg[\"num_review_pending\"] > 0) |\n",
    "    (sae_agg[\"num_action_pending\"] > 0)\n",
    ")\n",
    "\n",
    "# Case still open implies safety team not fully resolved\n",
    "sae_agg[\"pending_sae_safety_review_flag\"] = (\n",
    "    sae_agg[\"num_case_open\"] > 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe9c2287",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_count = (\n",
    "    sae_agg\n",
    "    .duplicated(subset=[\"study_id\", \"site_id\", \"subject_id\"])\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "assert dup_count == 0, \\\n",
    "    f\"SAE aggregation violates grain: {dup_count} duplicate rows\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "281a0f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_agg = sae_agg[\n",
    "    [\n",
    "        \"study_id\",\n",
    "        \"site_id\",\n",
    "        \"subject_id\",\n",
    "        \"open_sae_count\",\n",
    "        \"pending_sae_dm_review_flag\",\n",
    "        \"pending_sae_safety_review_flag\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ebcebac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.merge(\n",
    "    sae_agg,\n",
    "    on=[\"study_id\", \"site_id\", \"subject_id\"],\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4021419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No row explosion\n",
    "assert len(master_df) == len(cpid_df), \\\n",
    "    \"Row count changed after SAE join\"\n",
    "\n",
    "# Defaults for subjects with no SAE records\n",
    "master_df[\"open_sae_count\"] = (\n",
    "    master_df[\"open_sae_count\"]\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "master_df[\"pending_sae_dm_review_flag\"] = (\n",
    "    master_df[\"pending_sae_dm_review_flag\"]\n",
    "    .fillna(False)\n",
    "    .astype(bool)\n",
    ")\n",
    "\n",
    "master_df[\"pending_sae_safety_review_flag\"] = (\n",
    "    master_df[\"pending_sae_safety_review_flag\"]\n",
    "    .fillna(False)\n",
    "    .astype(bool)\n",
    ")\n",
    "\n",
    "# Final sanity\n",
    "assert (master_df[\"open_sae_count\"] >= 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58406c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
